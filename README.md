# üéÆ RPS Playground ‚Äî Algorithm Battle Arena

A modular Rock-Paper-Scissors algorithm testing playground with **32 built-in bots**, **Elo ratings**, **three competition modes**, and a beautiful **dark-themed Web UI**.

---

## üì¶ Setup

```bash
# Install the only dependency
pip3 install flask

# Clone / navigate to the project
cd /path/to/fun
```

---

## üöÄ Quick Start

### Web UI (recommended)

```bash
python3 -m rps_playground.web
```

Open **http://localhost:5000** in your browser.

### CLI

```bash
# List all algorithms
python3 -m rps_playground.main --list

# Head-to-Head
python3 -m rps_playground.main head-to-head \
  --algo-a "Markov Predictor" --algo-b "Frequency Analyzer" \
  --rounds 1000 --seed 42

# One vs All
python3 -m rps_playground.main one-vs-all \
  --algo "Pattern Detector" --rounds 1000 --seed 42

# Full Tournament
python3 -m rps_playground.main tournament --rounds 1000 --seed 42

# Export results
python3 -m rps_playground.main tournament \
  --rounds 1000 --seed 42 --export json --output results.json
```

---

## üåê Web UI Guide

The web interface has **three tabs**:

### ‚öîÔ∏è Head-to-Head

Run a single match between any two algorithms.

1. **Select Algorithm A** and **Algorithm B** from the dropdowns
2. **Set rounds** (default 1000) ‚Äî more rounds = more statistically significant
3. **Set seed** (optional) ‚Äî for reproducible results; leave empty for random
4. Click **‚öîÔ∏è FIGHT!**
5. View the result card showing wins, losses, draws, win %, and **Elo change**

### üèÜ Tournament

Full round-robin ‚Äî every algorithm plays every other algorithm (496 matches total with 32 bots).

1. **Set rounds per match** and optional **seed**
2. Click **üèÜ RUN**
3. View the **leaderboard** sorted by Elo rating
4. Scroll down to see the **Head-to-Head matrix** (W/L/D for every pairing)

### ü§ñ One vs All

Test a single algorithm against the entire pool of 32 bots.

1. **Select your algorithm** from the dropdown
2. **Set rounds** and optional **seed**
3. Click **ü§ñ RUN**
4. View **individual matchup results** (win/loss/draw for each opponent)
5. See the **overall ranking** table

---

## ü§ñ Algorithm Reference

All 32 algorithms explained:

### Static Strategies

| # | Algorithm | Strategy |
|---|-----------|----------|
| 1 | **Always Rock** | Plays Rock every round. Simple baseline ‚Äî easily exploited by Paper-playing bots. |
| 2 | **Always Paper** | Plays Paper every round. Beats constant Rock players but loses to Scissors. |
| 3 | **Always Scissors** | Plays Scissors every round. Completes the constant-move trio. |

### Randomized Strategies

| # | Algorithm | Strategy |
|---|-----------|----------|
| 4 | **Pure Random** | Picks Rock, Paper, or Scissors uniformly at random each round. Theoretically unbeatable in expectation (Nash equilibrium), but can't exploit predictable opponents. |
| 17 | **Weighted Random** | Picks moves randomly but **weighted by opponent's frequency** ‚Äî if opponent plays Rock often, this bot plays Paper more often. Adapts gradually. |
| 20 | **Chaos Strategy** | Randomly selects a **different sub-strategy each round** (random, counter-last, mirror, cycle, or frequency counter). Unpredictable but inconsistent. |

### Reactive Strategies

| # | Algorithm | Strategy |
|---|-----------|----------|
| 5 | **Cycle** | Plays Rock ‚Üí Paper ‚Üí Scissors ‚Üí Rock ‚Üí ... in a fixed repeating cycle. Predictable but guarantees equal distribution. |
| 6 | **Mirror Opponent** | Copies the opponent's **last move**. If they played Rock last round, plays Rock this round. Simple mimicry. |
| 7 | **Tit-for-Tat** | Starts with Rock, then **mirrors the opponent's previous move**. Classic cooperative strategy from game theory. |
| 8 | **Anti-Tit-for-Tat** | Plays whatever **beats the opponent's last move**. If they played Rock, plays Paper. Direct counter-strategy. |
| 16 | **Last-Move Counter** | Identical to Anti-Tit-for-Tat but starts with a random move. Plays the move that **would have beaten** the opponent's previous move. |

### Analytical Strategies

| # | Algorithm | Strategy |
|---|-----------|----------|
| 9 | **Frequency Analyzer** | Tracks the **overall frequency** of opponent's moves. Plays the counter to their most common move. Exploits opponents with strong biases. |
| 10 | **Markov Predictor** | Builds a **first-order Markov chain** of opponent transitions (e.g., "after Rock, they usually play Paper"). Predicts next move from the transition table and counters it. |
| 11 | **Pattern Detector** | Looks for **repeating n-gram patterns** (length 2-5) in opponent history. If a pattern is found, predicts and counters the next move. Falls back to counter-last. |
| 13 | **Meta-Predictor** | Runs **three sub-predictors** (frequency, last-move-repeat, anti-last) simultaneously. Tracks which predictor has been most accurate and follows the best one. Ensemble approach. |

### Adaptive Strategies

| # | Algorithm | Strategy |
|---|-----------|----------|
| 12 | **Win-Stay, Lose-Shift** | If it **won or drew** the last round, repeats the same move. If it **lost**, switches to what would have beaten the opponent. Classic reinforcement principle. |
| 14 | **Noise Strategy** | 80% of the time plays the **counter to opponent's most common move**. 20% of the time plays **randomly**. The noise prevents easy counter-exploitation. |
| 15 | **Adaptive Hybrid** | Runs three sub-strategies (frequency counter, mirror, random) and tracks their **win rates over time**. Every 50 rounds, switches to the strategy performing best. |

### Punishment Strategies

| # | Algorithm | Strategy |
|---|-----------|----------|
| 18 | **Punisher** | Plays randomly by default. When it **detects the opponent repeating a move 3+ times**, enters "punish mode" for 10 rounds ‚Äî aggressively countering their most common recent move. |
| 19 | **Forgiver** | Like Punisher, but **forgives after only 3 rounds** instead of 10. More lenient ‚Äî returns to random play quickly, giving the opponent a chance to change. |

### üß† Creative: Intelligence & Prediction

| # | Algorithm | Strategy |
|---|-----------|----------|
| 21 | **Decay Analyzer** | Like Frequency Analyzer, but uses **exponential decay weighting** (factor 0.9) so recent moves matter far more than old ones. Adapts within 10-20 rounds instead of hundreds. |
| 22 | **Historian** | Finds the **longest matching subsequence** from earlier in the game history and predicts what the opponent played next after that same context. Inspired by **LZ compression** ‚Äî longer context = better prediction. |
| 32 | **Iocaine Powder** | Legendary RPS bot. Runs **6 meta-strategies** simultaneously (naive, counter, counter-counter, and their opponent-perspective mirrors). Scores each by accuracy and follows the best. Named after *The Princess Bride*: "I know that you know that I know..." |

### üé≠ Creative: Psychology & Mind Games

| # | Algorithm | Strategy |
|---|-----------|----------|
| 23 | **Reverse Psychologist** | **2nd-order thinking**: "I played X ‚Üí opponent expects X again ‚Üí they'll play counter(X) ‚Üí I play counter(counter(X))". Beats naive counter-last strategies but loses to simple repeaters. |
| 28 | **Second Guess** | Like Reverse Psychologist, but **monitors whether the opponent actually IS countering** before committing to 2nd-order logic. Falls back to frequency analysis if opponent isn't counter-playing. |
| 24 | **Echo** | Copies the opponent's move from **3 rounds ago** instead of last round. Creates temporal confusion for strategies that only track immediate history. |

### üé™ Creative: Deception & Manipulation

| # | Algorithm | Strategy |
|---|-----------|----------|
| 25 | **Trojan Horse** | Plays **Always Rock for 30 rounds** as bait, tricking adaptive opponents into locking onto Paper. Then **abruptly switches** to countering their recent adaptation. The classic bait-and-switch. |
| 30 | **Phase Shifter** | Alternates between **40 rounds of aggressive exploitation** and **20 rounds of pure randomness**. The random bursts reset the opponent's model of it, preventing counter-adaptation. |
| 31 | **De Bruijn Walker** | Follows a **De Bruijn sequence** that covers all 9 possible 2-grams (RR, RP, RS, PR, PP, PS, SR, SP, SS). Pattern detectors can't find repeating subsequences. Occasionally (10%) deviates to exploit strong biases. |

### üßÆ Creative: Statistical & Ensemble

| # | Algorithm | Strategy |
|---|-----------|----------|
| 26 | **Reluctant Gambler** | Plays **pure random until statistically confident** (chi-squared test, p<0.05) that opponent has a bias. Then exploits hard. Re-checks every 100 rounds. Never commits without evidence. |
| 27 | **Entropy Guardian** | Monitors its **own move entropy**. If it detects itself becoming predictable (entropy drops below 70% of max), forces random play. Otherwise exploits normally. Balances attack and stealth. |
| 29 | **Majority Rule** | Runs **5 independent strategies** each round (counter-last, mirror, frequency, anti-cycle, random) and uses **majority vote** to pick the final move. Wisdom of crowds ‚Äî robust against many opponent types. |

---

## üìä Elo Rating System

- **Starting Elo**: 1500 for all algorithms
- **K-factor**: 32 (standard competitive)
- **Match outcomes**: Win = 1.0, Draw = 0.5, Loss = 0.0
- **Formula**: Standard Elo expected score calculation

```
E(A) = 1 / (1 + 10^((R_B - R_A) / 400))
R'(A) = R(A) + K √ó (S(A) - E(A))
```

Elo ratings are computed **chronologically** across all matches in a tournament, so the order of play matters. Leaderboards are sorted by Elo.

---

## üîß Adding Custom Algorithms

1. Open `rps_playground/algorithms.py`
2. Create a new class:

```python
class MyAlgorithm(Algorithm):
    name = "My Algorithm"

    def choose(self, round_num, my_history, opp_history):
        # round_num: current round (0-indexed)
        # my_history: list of your past Move choices
        # opp_history: list of opponent's past Move choices
        # self.rng: seeded Random instance for reproducibility
        return Move.ROCK  # your logic here
```

3. Add it to the registry:

```python
ALL_ALGORITHM_CLASSES = [
    ...,
    MyAlgorithm,  # add here
]
```

4. It instantly appears in both the CLI and Web UI.

---

## üìÅ Project Structure

```
rps_playground/
‚îú‚îÄ‚îÄ __init__.py          # Package init
‚îú‚îÄ‚îÄ engine.py            # Core: Move enum, winner logic, MatchResult, run_match
‚îú‚îÄ‚îÄ algorithms.py        # 32 algorithms + base class + registry
‚îú‚îÄ‚îÄ tournament.py        # 3 modes: head-to-head, one-vs-all, round-robin
‚îú‚îÄ‚îÄ stats.py             # Elo system, leaderboard, H2H matrix, pretty-print
‚îú‚îÄ‚îÄ export.py            # JSON and CSV export
‚îú‚îÄ‚îÄ main.py              # CLI entry point (argparse)
‚îú‚îÄ‚îÄ web.py               # Flask web server
‚îî‚îÄ‚îÄ templates/
    ‚îî‚îÄ‚îÄ index.html       # Web UI frontend
```

---

## ‚öôÔ∏è CLI Reference

```
python3 -m rps_playground.main <command> [options]

Commands:
  head-to-head   Mode 1: Algo A vs Algo B
  one-vs-all     Mode 2: Custom algo vs all 32 bots
  tournament     Mode 3: Full round-robin tournament

Global:
  --list         List all available algorithms

Options (all commands):
  --rounds N     Rounds per match (default: 1000)
  --seed S       RNG seed for reproducibility
  --export FMT   Export format: json | csv
  --output PATH  Export file path

head-to-head only:
  --algo-a NAME  Name of algorithm A
  --algo-b NAME  Name of algorithm B

one-vs-all only:
  --algo NAME    Name of your algorithm
```

---

## üé≤ Reproducibility

Use the `--seed` flag (CLI) or seed field (Web UI) to get **identical results** across runs:

```bash
# These two runs produce identical output
python3 -m rps_playground.main tournament --rounds 1000 --seed 42
python3 -m rps_playground.main tournament --rounds 1000 --seed 42
```

Each algorithm receives its own deterministic RNG derived from the master seed.

---

## üì§ Export

```bash
# JSON ‚Äî full match data + leaderboard + H2H matrix
python3 -m rps_playground.main tournament --export json --output results.json

# CSV ‚Äî leaderboard table only
python3 -m rps_playground.main tournament --export csv --output results.csv
```

---

*Built with Python üêç + Flask*
